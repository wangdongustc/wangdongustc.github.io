<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>简单的爬虫 imgur python spider | 小叮当走失在1995</title>
  <meta name="author" content="Darren Wang">
  
  <meta name="description" content="0x00 imgur.com: 一个随便看图的网站imgur 上的图都是大家上传的，首先 imgur 不允许用户上传 Copyright 有问题的图，因此下载这些图应该也是合法的。但是这些图的确不是很容易批量下载，正好正在学习 python，因此打算写一个 Python 的爬虫，来抓取感兴趣的图片来下载。写好的代码在：wangdongustc/imgur_downloader
当然如果是想要引用的话，直接下载或者使用 embedded code 也是可以的。如下～ （So adorable –）
Dog gets prosthetic limbs">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="简单的爬虫 imgur python spider"/>
  <meta property="og:site_name" content="小叮当走失在1995"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/blog/favicon.png" rel="icon">
  <link rel="alternate" href="/blog/atom.xml" title="小叮当走失在1995" type="application/atom+xml">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/blog/">小叮当走失在1995</a></h1>
  <h2><a href="/blog/">苟利国家生死以，岂因祸福避趋之</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/blog/">Home</a></li>
    
      <li><a href="/blog/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-30T16:00:00.000Z"><a href="/blog/2016/07/31/imgur-python-spider/">2016-07-31</a></time>
      
      
  
    <h1 class="title">简单的爬虫 imgur python spider</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="0x00-imgur-com-一个随便看图的网站"><a href="#0x00-imgur-com-一个随便看图的网站" class="headerlink" title="0x00 imgur.com: 一个随便看图的网站"></a>0x00 imgur.com: 一个随便看图的网站</h2><p>imgur 上的图都是大家上传的，首先 imgur 不允许用户上传 Copyright 有问题的图，因此下载这些图应该也是合法的。但是这些图的确不是很容易批量下载，正好正在学习 python，因此打算写一个 Python 的爬虫，来抓取感兴趣的图片来下载。写好的代码在：<a href="https://github.com/wangdongustc/imgur_downloader" target="_blank" rel="noopener">wangdongustc/imgur_downloader</a></p>
<p>当然如果是想要引用的话，直接下载或者使用 embedded code 也是可以的。如下～ （So adorable –）</p>
<p><div markdown="0"><blockquote class="imgur-embed-pub" lang="en" data-id="ualSlAg"><a href="//imgur.com/ualSlAg">Dog gets prosthetic limbs</a></blockquote><script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script></div><br><a id="more"></a></p>
<h2 id="0x01-爬虫所需的库"><a href="#0x01-爬虫所需的库" class="headerlink" title="0x01 爬虫所需的库"></a>0x01 爬虫所需的库</h2><p>首先我用的是 Python3，所用的库也就是 <a href="http://docs.python-requests.org/en/master/user/install/" target="_blank" rel="noopener">requests</a> 和 <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="noopener">BeautifulSoup</a>，可以用 pip 下载：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure></p>
<h2 id="0x02-网页抓取和分析代码"><a href="#0x02-网页抓取和分析代码" class="headerlink" title="0x02 网页抓取和分析代码"></a>0x02 网页抓取和分析代码</h2><p>用法都十分的简单，比如使用 requests 加载一个网页，并用 bs4 去分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    user_agent = &#123;<span class="string">'User-agent'</span>: <span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">    response = requests.get(http_url, headers=user_agent)</span><br><span class="line">    <span class="keyword">if</span> response.status_code != <span class="number">200</span>:</span><br><span class="line">        print(<span class="string">'Page Load Error! Skipping...'</span>)</span><br><span class="line">        print()</span><br><span class="line">        <span class="keyword">return</span> set()</span><br><span class="line">    html_doc = response.text</span><br><span class="line">    soup = BeautifulSoup(html_doc, <span class="string">"html5lib"</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"Get error. Skipping...\n"</span>)</span><br><span class="line">    <span class="keyword">return</span> set()</span><br></pre></td></tr></table></figure></p>
<p>使用 bs4 分析网站的 a 标签，并检测分析到的连接中符合要求的网页：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">url_set = set()</span><br><span class="line">link_list = soup.find_all(<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> link_list:</span><br><span class="line">    url_tmp = x.get(<span class="string">'href'</span>)</span><br><span class="line">    <span class="comment"># filter the urls to maintain only ones from imgur.com and have not been crawled</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'https://'</span> <span class="keyword">not</span> <span class="keyword">in</span> url_tmp <span class="keyword">and</span> <span class="string">'http://'</span> <span class="keyword">not</span> <span class="keyword">in</span> url_tmp:</span><br><span class="line">        url_tmp = <span class="string">"https://imgur.com"</span> + url_tmp</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'reddit.com'</span> <span class="keyword">in</span> url_tmp:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'https://imgur.com'</span> <span class="keyword">not</span> <span class="keyword">in</span> url_tmp:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> url_tmp <span class="keyword">in</span> history_url:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># add the filtered link to a url set</span></span><br><span class="line">    url_set.add(url_tmp)</span><br><span class="line">history_url.add(url_tmp);</span><br></pre></td></tr></table></figure></p>
<p>这里只保留 imgur.com 的链接，以保证爬虫在爬取过程中始终保留在 imgur.com 上。另外，如果链接已经被爬过，则排除该链接。（忽然想这样其实可以计算 imgur.com 的 pagerank，如果抓取量够得大的话。）</p>
<h2 id="0x03-广度优先搜索"><a href="#0x03-广度优先搜索" class="headerlink" title="0x03 广度优先搜索"></a>0x03 广度优先搜索</h2><p>其实很简单的一个搜索，每次爬完手头的链接，再继续爬下一层。可以加上多线程抓取，会快不少。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(depth &lt; <span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> depth == <span class="number">-1</span>:</span><br><span class="line">        depth = <span class="number">0</span></span><br><span class="line">        url_set = CrawlPages(init_url, history_url)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        depth += <span class="number">1</span></span><br><span class="line">        result_set = set()</span><br><span class="line">        <span class="keyword">for</span> sub_url <span class="keyword">in</span> url_set:</span><br><span class="line">            print(<span class="string">"Depth:"</span>, depth)</span><br><span class="line">            result_set |= CrawlPages(sub_url, history_url)</span><br><span class="line">url_set = result_set</span><br></pre></td></tr></table></figure></p>
<h2 id="0x04-图片下载"><a href="#0x04-图片下载" class="headerlink" title="0x04 图片下载"></a>0x04 图片下载</h2><p>下载的话直接调用 requests 然后二进制格式写入文件就可以了。只不过 imgur.com 使用了 js 还是别的控件，导致 GET 到的 html 中并没有图片的下载链接。但其实如果知道页面的链接，下载的链接也就出来了，如下：</p>
<p>页面链接：<a href="https://imgur.com/r/puppies/TvnyjEc" target="_blank" rel="noopener">https://imgur.com/r/puppies/TvnyjEc</a><br>下载链接：<a href="http://imgur.com/download/TvnyjEc/" target="_blank" rel="noopener">http://imgur.com/download/TvnyjEc/</a> + 图片名称</p>
<p>图片直接保存成 .gif， 这样就比较不容易丢失动画信息。好吧其实我也是想抓动图来着。</p>
<p>图片的筛选就比较麻烦了，其实可以根据 r/ 后面的信息来筛选 topic， 也有的链接是 /topic 的链接，那在这个页面上抓取的就默认为该话题的图片啦。</p>
<h2 id="0x05-链接，后记"><a href="#0x05-链接，后记" class="headerlink" title="0x05 链接，后记"></a>0x05 链接，后记</h2><p>在国内就已经知道 imgur 中有比较神奇的图片的存在。 在 <a href="https://github.com/wangdongustc/imgur_downloader" target="_blank" rel="noopener">github</a> 中的链接就比较神奇，可以打开看一下。这些图一般比较大，这种爬虫在爬到第三层的时候就没有新的页面可以爬了，就停下了。</p>
<p><strong>不要想着搞出什么大新闻，自己知道就好！</strong><br><strong>不要想着搞出什么大新闻，自己知道就好！</strong><br><strong>不要想着搞出什么大新闻，自己知道就好！</strong></p>

      
    </div>
    <footer>
      
        
        
        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>
<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="" data-title="简单的爬虫 imgur python spider" data-url=""></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"wangdong115"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->

</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:www.wangdongustc.com/blog">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/blog/tags/chromebook/">chromebook</a><small>2</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  <table align="center" id="claimtable">
		<tr>
			<td>特别鸣谢：我的家人，朋友，老师，以及</td>
			<td><div class="item" > &nbsp;我的女朋友文文妹<div class="tooltip" style="z-index:3"><img src="/img/gf.png" width="280px"><div class="arrow"></div></div>
			<div class="dropface"><img src="/img/qq.png" style="margin-left:47px"></div>	
			
			</div>
			</td>
			<td>感谢他们一直以来的支持与陪伴~</td>
		</tr>
  </table>
  </br>
  
  &copy; 2018 &nbsp;Darren Wang.&nbsp;
  Bring to You by <a href="https://hexo.io/" target="_blank">Hexo</a> on <a href="https://github.com/" target="_blank">Github</a>. &nbsp;
  Your IP:<script language="JavaScript" type="text/javascript" src=http://home.ustc.edu.cn/cgi-bin/myip> </script>.&nbsp;
  
  Access Count:
  <!-- Start of StatCounter Code for Default Guide -->
		<script type="text/javascript">
		var sc_project=10001089; 
		var sc_invisible=0; 
		var sc_security="c0df197e"; 
		var sc_text=2; 
		var scJsHost = (("https:" == document.location.protocol) ?
		"https://secure." : "http://www.");
		document.write("<sc"+"ript type='text/javascript' src='" +
		scJsHost+
		"statcounter.com/counter/counter.js'></"+"script>");
		</script>
		<noscript>
		<div class="statcounter"><a title="shopify site
		analytics" href="http://statcounter.com/shopify/"
		target="_blank"><img class="statcounter"
		src="http://c.statcounter.com/10001089/0/c0df197e/0/"
		alt="shopify site analytics"></a></div>
		</noscript>
<!-- End of StatCounter Code for Default Guide -->.

  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>




<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
